{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EashwarPrabu/gaied-lpmcai-main/blob/main/code/src/GenAI_LPMC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "DZNWqvfAZmxg",
        "outputId": "daba46e4-6582-4c71-812f-a0d729570bbe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.44.0-py3-none-any.whl.metadata (8.9 kB)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.50.0)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.5.2)\n",
            "Collecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.45.4-py3-none-manylinux_2_24_x86_64.whl.metadata (5.0 kB)\n",
            "Collecting xformers\n",
            "  Downloading xformers-0.0.29.post3-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: pyYAML in /usr/local/lib/python3.11/dist-packages (6.0.2)\n",
            "Collecting jaydebeapi\n",
            "  Downloading JayDeBeApi-1.2.3-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting pdfplumber\n",
            "  Downloading pdfplumber-0.11.5-py3-none-any.whl.metadata (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.5/42.5 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pypandoc\n",
            "  Downloading pypandoc-1.15-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting python-docx\n",
            "  Downloading python_docx-1.1.2-py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting bs4\n",
            "  Downloading bs4-0.0.2-py2.py3-none-any.whl.metadata (411 bytes)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.1.8)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.1.0)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.4)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.0.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.12.2)\n",
            "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.29.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.6.0+cu124)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Collecting JPype1 (from jaydebeapi)\n",
            "  Downloading jpype1-1.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting pdfminer.six==20231228 (from pdfplumber)\n",
            "  Downloading pdfminer.six-20231228-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting pypdfium2>=4.18.0 (from pdfplumber)\n",
            "  Downloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20231228->pdfplumber) (3.4.1)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20231228->pdfplumber) (43.0.3)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (5.3.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from bs4) (4.13.3)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.31.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.1.31)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->bs4) (2.6)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (1.17.1)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.23.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (2.22)\n",
            "Downloading streamlit-1.44.0-py3-none-any.whl (9.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.8/9.8 MB\u001b[0m \u001b[31m95.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bitsandbytes-0.45.4-py3-none-manylinux_2_24_x86_64.whl (76.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.0/76.0 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xformers-0.0.29.post3-cp311-cp311-manylinux_2_28_x86_64.whl (43.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.4/43.4 MB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m77.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m61.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m99.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading JayDeBeApi-1.2.3-py3-none-any.whl (26 kB)\n",
            "Downloading pdfplumber-0.11.5-py3-none-any.whl (59 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdfminer.six-20231228-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m112.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypandoc-1.15-py3-none-any.whl (21 kB)\n",
            "Downloading python_docx-1.1.2-py3-none-any.whl (244 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.3/244.3 kB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bs4-0.0.2-py2.py3-none-any.whl (1.2 kB)\n",
            "Downloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m95.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m87.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jpype1-1.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (494 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m494.1/494.1 kB\u001b[0m \u001b[31m40.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: watchdog, python-docx, pypdfium2, pypandoc, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, JPype1, pydeck, nvidia-cusparse-cu12, nvidia-cudnn-cu12, jaydebeapi, bs4, pdfminer.six, nvidia-cusolver-cu12, pdfplumber, xformers, streamlit, bitsandbytes\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed JPype1-1.5.2 bitsandbytes-0.45.4 bs4-0.0.2 jaydebeapi-1.2.3 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pdfminer.six-20231228 pdfplumber-0.11.5 pydeck-0.9.1 pypandoc-1.15 pypdfium2-4.30.1 python-docx-1.1.2 streamlit-1.44.0 watchdog-6.0.0 xformers-0.0.29.post3\n"
          ]
        }
      ],
      "source": [
        "!pip install streamlit transformers accelerate bitsandbytes xformers pyYAML jaydebeapi pdfplumber pypandoc python-docx bs4"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(\"CUDA Available:\", torch.cuda.is_available())\n",
        "print(\"Device:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU found\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9o5QkDvEZxyT",
        "outputId": "2ab3c644-d68e-4a29-b84c-ef3b7713e60c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA Available: True\n",
            "Device: Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q -O - ipv4.icanhazip.com"
      ],
      "metadata": {
        "id": "-LB_Cht6aCab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import email\n",
        "import hashlib\n",
        "import os\n",
        "import logging\n",
        "from email import policy\n",
        "from email.parser import BytesParser\n",
        "from email.message import Message\n",
        "import base64\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "import torch\n",
        "import json\n",
        "import yaml\n",
        "import ast\n",
        "import jaydebeapi\n",
        "import pdfplumber\n",
        "import pypandoc\n",
        "from docx import Document\n",
        "from bs4 import BeautifulSoup\n",
        "import sqlite3\n",
        "\n",
        "# Set up logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Setup Sqlite3 DB and store it in Streamlit session to ensure DB connections are not loaded up in every render of application\n",
        "def setup_sqlite_database():\n",
        "    if \"db_conn\" not in st.session_state:\n",
        "        conn = sqlite3.connect(\"lmpc_genai_db.sqlite\", check_same_thread=False)\n",
        "        cursor = conn.cursor()\n",
        "        cursor.execute(\"\"\"\n",
        "            CREATE TABLE IF NOT EXISTS emails (\n",
        "                id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "                filename VARCHAR(255),\n",
        "                sender VARCHAR(255),\n",
        "                request_type VARCHAR(255),\n",
        "                sub_request_type TEXT,\n",
        "                confidence VARCHAR(255),\n",
        "                email_hash VARCHAR(255)\n",
        "            )\n",
        "        \"\"\")\n",
        "        conn.commit()  # Save table creation\n",
        "        st.session_state[\"db_conn\"] = conn\n",
        "        st.session_state[\"db_cursor\"] = cursor\n",
        "        logger.info(\"SQLite database setup complete.\")\n",
        "\n",
        "    return st.session_state[\"db_conn\"], st.session_state[\"db_cursor\"]\n",
        "\n",
        "\n",
        "# Load and cache the model using Streamlit cache resource annotation to ensure app doesn't reload during every render\n",
        "@st.cache_resource\n",
        "def load_model():\n",
        "    bnb_config = BitsAndBytesConfig(\n",
        "        load_in_4bit=True,  # Use 4-bit quantization\n",
        "        bnb_4bit_compute_dtype=torch.float16,  # Use float16 for computation\n",
        "        bnb_4bit_quant_type=\"nf4\",  # More efficient quantization type\n",
        "        bnb_4bit_use_double_quant=True  # Extra compression\n",
        "    )\n",
        "\n",
        "    model_name = \"mistralai/Mistral-7B-Instruct-v0.3\"\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        model_name,\n",
        "        quantization_config=bnb_config,\n",
        "        device_map=\"auto\"\n",
        "    )\n",
        "    logger.info(f\"Loading model from cache...\")\n",
        "    return model, tokenizer\n",
        "\n",
        "model, tokenizer = load_model()\n",
        "\n",
        "# Parse the configuration (request, sub-request and keyword) that will be passed as prompt to LLM\n",
        "def config_parser():\n",
        "  logger.info(f\"Parsing configuration from yml file...\")\n",
        "  with open(\"DetectionTypes.yml\", \"r\") as f:\n",
        "    config = yaml.safe_load(f)\n",
        "  return config\n",
        "\n",
        "config = config_parser()\n",
        "request_types = [ request for request in config.keys()]\n",
        "\n",
        "# Prompt Template for the classification task\n",
        "classification_prompt = \"\"\"\n",
        "You are a expert helping users to categorize the text based on predefined classes. Only categorize the content based on the available list of classes.\n",
        "Given an input text, classify it into one of the **main request types**: {request_types} and, if applicable, further classify it into a **sub-request** type.\n",
        "Your response **must only** be a JSON dictionary with: {outputFormat}\n",
        "\n",
        "### **Classification Rules**:\n",
        "- **Request Type:** Match the text to the most relevant **Request type** based on its semantics, meaning and the sample list of keywords.\n",
        "- **Sub-Request Type:** If the text aligns with a sub-category, classify it accordingly.\n",
        "- The following are some of the example Request-Types, their sample reference keywords and Sub-Request Types.\n",
        "{config}\n",
        "\n",
        "Text: \"{input_text}\"\n",
        "\n",
        "Output:\n",
        "\"\"\"\n",
        "# Prompt Template for the Name-Entity Recognition task to identify the key-value pairs\n",
        "ner_prompt = \"\"\"\n",
        "You are a financial expert who is responsible identifying all the important key value pairs associated with Finance/Banking, etc.\n",
        "Extract financial details from the given content and return them **strictly as a dictionary of key-value pairs**.\n",
        "Text: \"{input_text}\"\n",
        "\n",
        "Output:\n",
        "\"\"\"\n",
        "# Structure of Classification output\n",
        "classificationOutputFormat = {\n",
        "    \"output\": {\n",
        "    \"requestType\": \"string\",\n",
        "    \"subRequestTypes\": [\"string\"],\n",
        "    \"probability\": \"float\",\n",
        "    \"reasoning\": \"string\"\n",
        "  }\n",
        "}\n",
        "\n",
        "# Tokenizes the input text (prompt and the email content) into tensors and invokes the model\n",
        "# Decodes the tensors back to string and returns the response\n",
        "def invoke(prompt):\n",
        "  # Ensure pad_token is properly set\n",
        "  if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token  # Assign pad_token explicitly\n",
        "\n",
        "  # Tokenize input with attention mask\n",
        "  inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "  input_ids = inputs[\"input_ids\"].to(model.device)\n",
        "  attention_mask = inputs[\"attention_mask\"].to(model.device)\n",
        "\n",
        "  # Generate output with explicit attention mask\n",
        "  output = model.generate(\n",
        "    input_ids,\n",
        "    attention_mask=attention_mask,  # Pass attention_mask explicitly\n",
        "    max_length=4096,\n",
        "    pad_token_id=tokenizer.pad_token_id  # Use correct pad_token_id\n",
        "  )\n",
        "\n",
        "  # Decode and Extract JSON Output\n",
        "  response = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "\n",
        "  # Extract only the JSON output\n",
        "  if \"Output:\" in response:\n",
        "      response = response.split(\"Output:\")[-1].strip()\n",
        "\n",
        "  return response\n",
        "\n",
        "# Classify takes content of mail as parameter, creates the classification prompt and then calls invoke function to get LLM response\n",
        "def classify(input_text):\n",
        "    formatted_prompt = classification_prompt.format(\n",
        "        input_text=input_text,\n",
        "        outputFormat=classificationOutputFormat,\n",
        "        request_types=request_types,\n",
        "        config=config)\n",
        "    classifiedOutput = invoke(formatted_prompt)\n",
        "    logger.info(f\"Classified results: {classifiedOutput}\")\n",
        "    return ast.literal_eval(classifiedOutput)\n",
        "\n",
        "# Extract takes content of mail as parameter, creates the NER prompt and then calls invoke function to get LLM response\n",
        "def extract(input_text):\n",
        "    formatted_prompt = ner_prompt.format(input_text=input_text)\n",
        "    extractedOutput = invoke(formatted_prompt)\n",
        "    logger.info(f\"Extracted results: {extractedOutput}\")\n",
        "    return json.loads(extractedOutput)\n",
        "\n",
        "# Wrapper for Classify and Extract methods, responsible for concatenating all the output\n",
        "def classify_and_extract(input_text):\n",
        "    classifiedResult = classify(input_text)\n",
        "    extractedResult = extract(input_text)\n",
        "    logger.info(f\"Final classification results: {classifiedResult}\")\n",
        "    logger.info(f\"Final extraction results: {extractedResult}\")\n",
        "\n",
        "    classifiedResult[\"nameValuePairs\"] = extractedResult\n",
        "    print(classifiedResult)\n",
        "    return classifiedResult\n",
        "\n",
        "# Directory to store attachments\n",
        "ATTACHMENTS_DIR = \"attachments/\"\n",
        "os.makedirs(ATTACHMENTS_DIR, exist_ok=True)\n",
        "\n",
        "# Helper functions to parse the attachments based on their file type\n",
        "def process_attachment(file_path):\n",
        "    \"\"\"Reads and extracts text from PDF, DOCX, DOC, and TXT files.\"\"\"\n",
        "    try:\n",
        "        if file_path.endswith(\".pdf\"):\n",
        "            return extract_text_from_pdf(file_path)\n",
        "        elif file_path.endswith(\".docx\"):\n",
        "            return extract_text_from_docx(file_path)\n",
        "        elif file_path.endswith(\".doc\"):\n",
        "            return extract_text_from_doc(file_path)\n",
        "        elif file_path.endswith(\".txt\"):\n",
        "            return extract_text_from_txt(file_path)\n",
        "        else:\n",
        "            logger.warning(f\"Unsupported file type: {file_path}\")\n",
        "            return None\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error processing attachment {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    \"\"\"Extracts text from a PDF file.\"\"\"\n",
        "    try:\n",
        "        with pdfplumber.open(pdf_path) as pdf:\n",
        "            text = \"\\n\".join([page.extract_text() for page in pdf.pages if page.extract_text()])\n",
        "        return text if text else \"(No readable text in PDF)\"\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error reading PDF {pdf_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def extract_text_from_docx(docx_path):\n",
        "    \"\"\"Extracts text from a DOCX file.\"\"\"\n",
        "    try:\n",
        "        doc = Document(docx_path)\n",
        "        text = \"\\n\".join([para.text for para in doc.paragraphs])\n",
        "        return text if text else \"(No readable text in DOCX)\"\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error reading DOCX {docx_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def extract_text_from_doc(doc_path):\n",
        "    \"\"\"Extracts text from a DOC file using pypandoc.\"\"\"\n",
        "    try:\n",
        "        return pypandoc.convert_file(doc_path, \"plain\")\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error reading DOC {doc_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def extract_text_from_txt(txt_path):\n",
        "    \"\"\"Extracts text from a TXT file.\"\"\"\n",
        "    try:\n",
        "        with open(txt_path, \"r\", encoding=\"utf-8\") as f:\n",
        "            return f.read().strip()\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error reading TXT {txt_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "# Parses the file uploaded through UI.\n",
        "# Walks through all the email content and its attachment and returns them\n",
        "def parse_eml(file):\n",
        "    try:\n",
        "        msg: Message = BytesParser(policy=policy.default).parse(file)\n",
        "        logger.info(\"Email content classifier\")\n",
        "\n",
        "        subject = msg[\"subject\"] or \"No Subject\"\n",
        "        sender = msg[\"from\"]\n",
        "        recipient = msg[\"to\"]\n",
        "        date = msg[\"date\"]\n",
        "        body = \"\"\n",
        "        attachments = []\n",
        "\n",
        "        # Extract body and attachments\n",
        "        for part in msg.walk():\n",
        "            content_type = part.get_content_type()\n",
        "\n",
        "            if content_type == \"text/plain\":\n",
        "                body += part.get_payload(decode=True).decode(errors=\"ignore\")\n",
        "            elif content_type == \"text/html\":\n",
        "                html_content = part.get_payload(decode=True).decode(errors=\"ignore\")\n",
        "                soup = BeautifulSoup(html_content, \"html.parser\")\n",
        "                body += soup.get_text(separator=\" \") + \"\\n\"\n",
        "            elif part.get_content_disposition() == \"attachment\":\n",
        "                attachment_name = part.get_filename()\n",
        "                attachment_data = part.get_payload(decode=True)\n",
        "\n",
        "                if not attachment_name or not attachment_data:\n",
        "                    continue  # Skip if no valid attachment\n",
        "\n",
        "                # Save the attachment file locally\n",
        "                file_path = os.path.join(ATTACHMENTS_DIR, attachment_name)\n",
        "                with open(file_path, \"wb\") as f:\n",
        "                    f.write(attachment_data)\n",
        "\n",
        "                # Try to extract text from known file types\n",
        "                extracted_text = process_attachment(file_path)\n",
        "\n",
        "                if extracted_text:\n",
        "                    attachment_type = \"text\"\n",
        "                    attachment_content = extracted_text  # Store extracted text\n",
        "                else:\n",
        "                    attachment_type = \"binary\"\n",
        "                    attachment_content = base64.b64encode(attachment_data).decode()  # Store Base64\n",
        "\n",
        "                logger.info(f\"Attachment found: {attachment_name} (Type: {attachment_type}, Size: {len(attachment_data)} bytes)\")\n",
        "\n",
        "                attachments.append({\n",
        "                    \"name\": attachment_name,\n",
        "                    \"type\": attachment_type,\n",
        "                    \"content\": attachment_content,  # Extracted text or Base64\n",
        "                    \"size\": len(attachment_data)\n",
        "                })\n",
        "\n",
        "        email_data = {\n",
        "            \"subject\": subject,\n",
        "            \"from\": sender,\n",
        "            \"to\": recipient,\n",
        "            \"date\": date,\n",
        "            \"body\": body,\n",
        "            \"attachments\": attachments  # List of extracted attachments\n",
        "        }\n",
        "\n",
        "        logger.info(f\"Email components extracted: {subject}\")\n",
        "        return email_data\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error parsing email: {e}\")\n",
        "        return {\"error\": str(e)}\n",
        "\n",
        "# Computes the hash using the email sender and email content\n",
        "def compute_hash(email_data):\n",
        "    text = email_data['subject'] + email_data['body']\n",
        "    email_hash = hashlib.md5(text.encode()).hexdigest()\n",
        "    logger.info(f\"Hash computed: {email_hash}\")\n",
        "    return email_hash\n",
        "\n",
        "# Detects duplicates from DB using email sender and email hash\n",
        "def detect_duplicates(cursor, email_data, email_hash):\n",
        "    logger.info(f\"Checking for duplicates: {email_data['filename']}\")\n",
        "    try:\n",
        "        cursor.execute(\"SELECT COUNT(*) FROM emails WHERE email_hash = ? AND sender = ?\",\n",
        "                       (email_hash, email_data['from']))\n",
        "        count = cursor.fetchone()[0]\n",
        "        is_duplicate = count > 0\n",
        "        data = None\n",
        "        if is_duplicate:\n",
        "          cursor.execute(\"SELECT * FROM emails WHERE email_hash = ? AND sender = ?\",\n",
        "                       (email_hash, email_data['from']))\n",
        "          data = cursor.fetchone()\n",
        "          retrieved_data = {\n",
        "              \"isDuplicate\": True,\n",
        "              \"filename\": data[1],\n",
        "              \"sender\": data[2],\n",
        "              \"requestType\": data[3],\n",
        "              \"subRequestType\": data[4],\n",
        "              \"probability\": data[5],\n",
        "          }\n",
        "        logger.info(f\"Duplicate check result: {'Duplicate' if is_duplicate else 'Not a duplicate'}\")\n",
        "        logger.info(f\"Retrieved data: {data}\")\n",
        "        return is_duplicate, retrieved_data\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error detecting duplicates for {email_data['filename']}: {str(e)}\")\n",
        "        return False, None\n",
        "\n",
        "# Store the results for an email in Sqlite3 DB\n",
        "def store_email_data(cursor, email_data, output, email_hash):\n",
        "    sub_request_types = \"/\".join(output['output']['subRequestTypes'])\n",
        "    logger.info(f\"Storing email data for: {email_data['filename']}\")\n",
        "    try:\n",
        "        cursor.execute(\"\"\"\n",
        "            INSERT INTO emails (filename, sender, request_type, sub_request_type, confidence, email_hash)\n",
        "            VALUES (?, ?, ?, ?, ?, ?)\n",
        "        \"\"\", (\n",
        "            email_data['filename'],\n",
        "            email_data['from'],\n",
        "            output['output']['requestType'],\n",
        "            sub_request_types,\n",
        "            output['output']['probability'],\n",
        "            email_hash\n",
        "        ))\n",
        "        logger.info(\"Email data stored successfully.\")\n",
        "    except sqlite3.IntegrityError:\n",
        "        logger.warning(f\"Duplicate email detected, skipping storage: {email_data['filename']}\")\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error storing email data for {email_data['filename']}: {str(e)}\")\n",
        "\n",
        "\n",
        "# Streamlit app title\n",
        "st.title(\"GenAI LPMC - Email content classifier\")\n",
        "uploaded_file = st.file_uploader(\"Upload an .eml file\", type=[\"eml\"])\n",
        "\n",
        "if uploaded_file:\n",
        "    with uploaded_file:\n",
        "        filename = uploaded_file.name\n",
        "        uploaded_file.seek(0)  # Reset file pointer before reading\n",
        "        email_data = parse_eml(uploaded_file)\n",
        "        print(\"Updated contents\")\n",
        "        print(email_data)\n",
        "        email_data[\"filename\"] = filename\n",
        "        email_hash = compute_hash(email_data)\n",
        "        conn, cursor = setup_sqlite_database()\n",
        "        if conn and cursor:\n",
        "            isDuplicate, data = detect_duplicates(cursor, email_data, email_hash)\n",
        "            if isDuplicate and data:\n",
        "                logger.error(f\"Dupicate detected. Mail contents already exists in DB\")\n",
        "                st.write(\"Duplicated email detected. The results of the email are: \")\n",
        "                st.json(data)\n",
        "            else:\n",
        "                with st.spinner(f\"Processing email {filename}... Please wait ⏳\"):\n",
        "                    attachment_data = \"\"\n",
        "                    for attachment in email_data[\"attachments\"]:\n",
        "                        if attachment[\"type\"] == \"text\":\n",
        "                            attachment_data += \"\\n\\n--- Attachment: {} ---\\n{}\".format(attachment[\"name\"], attachment[\"content\"])\n",
        "                    result = classify_and_extract(email_data[\"body\"] + attachment_data)\n",
        "                    store_email_data(cursor, email_data, result, email_hash)\n",
        "                    conn.commit()\n",
        "                    output = {\n",
        "                        \"emailContents\": email_data,\n",
        "                        \"result\": result\n",
        "                    }\n",
        "                    st.json(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MUwOXWpNaC44",
        "outputId": "34fc6d0b-699b-4c63-db09-49be50cfe055"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "AwHpDVyYbGGt",
        "outputId": "c91fbda5-61a0-4630-8d26-5e32b0ebd865"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    To log in, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Enter your token (input will not be visible): \n",
            "Add token as git credential? (Y/n) n\n",
            "Token is valid (permission: fineGrained).\n",
            "The token `Hackathon-25` has been saved to /root/.cache/huggingface/stored_tokens\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful.\n",
            "The current active token is: `Hackathon-25`\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run app.py & npx localtunnel --port 8501"
      ],
      "metadata": {
        "collapsed": true,
        "id": "YTs8-XDraYL1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eea497bb-01aa-44a3-8b10-2396647a8a0e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.125.38.35:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rw90KUvcGQO_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
